import os
import sys
import logging
import pandas as pd
from typing import Dict, Any, Optional

from data_pipeline import data_pipeline
from model_training import ModelTrainer
from model_evaluation import ModelEvaluator
from model_building import XGboostModelBuilder, RandomForestModelBuilder
from config import get_model_config, get_data_paths

# ---------------------------------------------------------------------
# Logging Configuration
# ---------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------
# Training Pipeline
# ---------------------------------------------------------------------
def training_pipeline(
        data_path: str = 'data/raw/ChurnModelling.csv',
        model_params: Optional[Dict[str, Any]] = None,
        test_size: float = 0.2,
        random_state: int = 42,
        model_path: str = 'artifacts/models/Telco-Customer-Churn.joblib'
):
    logger.info("\n\nğŸš€ Starting Training Pipeline...\n\n")

    data_files = get_data_paths()
    required_files = ["X_train", "X_test", "Y_train", "Y_test"]

    # -----------------------------------------------------------------
    # Check if artifacts exist
    # -----------------------------------------------------------------
    logger.info("\n\nğŸ” Checking for cached data artifacts...\n\n")
    if not all(os.path.exists(data_files[file]) for file in required_files):
        logger.warning("ğŸ“ Data artifacts not found â€” running data pipeline...")
        data_pipeline()
    else:
        logger.info("ğŸ“¦ Loading existing data artifacts...")

    # -----------------------------------------------------------------
    # Load Data
    # -----------------------------------------------------------------
    logger.info("\n\nğŸ“¥ Reading training & test datasets...\n\n")
    X_train = pd.read_csv(data_files["X_train"])
    X_test = pd.read_csv(data_files["X_test"])
    Y_train = pd.read_csv(data_files["Y_train"])
    Y_test = pd.read_csv(data_files["Y_test"])

    # -----------------------------------------------------------------
    # Model Building
    # -----------------------------------------------------------------
    logger.info("\n\nğŸ§± Building model: XGBoost...\n\n")
    model_builder = XGboostModelBuilder()
    model = model_builder.build_model()

    # -----------------------------------------------------------------
    # Model Training
    # -----------------------------------------------------------------
    logger.info("\n\nğŸ‹ï¸â€â™‚ï¸ Training model...\n\n")
    trainer = ModelTrainer(param_grid=model_params)

    model, train_score = trainer.train(
        model=model,
        X_train=X_train,
        Y_train=Y_train
    )

    logger.info(f"âœ… Training Completed â€” Score: {train_score:.4f}")
    trainer.save_model(model, model_path)
    logger.info(f"ğŸ’¾ Model saved to: {model_path}")

    # -----------------------------------------------------------------
    # Evaluation
    # -----------------------------------------------------------------
    logger.info("\n\nğŸ“Š Evaluating model...\n\n")
    evaluator = ModelEvaluator(model, "XGBoost")
    evaluation_results = evaluator.evaluate(X_test, Y_test)

    # Remove confusion matrix before printing
    results_display = evaluation_results.copy()
    results_display.pop("cm", None)

    logger.info("âœ¨ Evaluation Results:")
    for k, v in results_display.items():
        logger.info(f"   - {k}: {v}")

    logger.info("\n\nğŸ Pipeline completed successfully! ğŸ‰\n\n")


# ---------------------------------------------------------------------
# Run Pipeline
# ---------------------------------------------------------------------
if __name__ == "__main__":
    model_config = get_model_config()
    model_params = model_config.get("model_params")

    training_pipeline(model_params=model_params)
